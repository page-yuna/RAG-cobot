{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDXrA1_BjlpW",
        "outputId": "f45cf5c6-623d-4ddf-ae35-2664f9dd9fa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/rag_final.py:4: LangChainDeprecationWarning: Importing FAISS from langchain.vectorstores is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.vectorstores import FAISS\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.vectorstores import FAISS\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.vectorstores import FAISS\n",
            "2025-06-19 11:35:13.001585: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750332913.020768   28476 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750332913.026673   28476 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Loading checkpoint shards: 100% 3/3 [00:17<00:00,  5.90s/it]\n",
            "Device set to use cuda:0\n",
            "\n",
            "❓ 질문 입력 (종료: exit): URScript에서 MoveJ 명령어에 블렌드 반경을 설정하려면 어떻게 해야 하나요?\n",
            "\n",
            "🟢 답변: ```\n",
            "robot.SetParameter(13, 반경_값)\n",
            "```\n",
            "반경_값은 원하는 값으로 설정하세요. 이 명령어는 자세히 설명된 것은 아니지만 블렌드 반경을 설정하는 데 사용할 수 있습니다.\n",
            "\n",
            "❓ 질문 입력 (종료: exit): URCap 개발 시 C207A0 오류는 무엇을 의미하나요?\n",
            "\n",
            "🟢 답변: C207A0 오류는 UR5 로봇 시뮬레이션에서 URCap을 로드하거나 실행할 때 발생할 수 있는 오류입니다. 이 오류는 대체 모듈이 허용되지 않은 패키지를 사용하여 발생할 수 있습니다. UR5 로봇 시뮬레이션 환경에서는 대체 모듈을 사용하지 않도록 하면 해결할 수 있습니다.\n",
            "\n",
            "❓ 질문 입력 (종료: exit): UR5e의 0번 포트에서 아날로그 입력을 읽으려면 어떻게 하나요?\n",
            "\n",
            "🟢 답변: UR5e의 0번 포트는 아날로그 입력을 받을 수 있는 포트는 아닙니다. 이를 위해서는 다른 포트를 사용해야 합니다.\n",
            "\n",
            "❓ 질문 입력 (종료: exit): URScript에서 루프 내부에서 서브프로그램을 호출할 수 있나요?\n",
            "\n",
            "🟢 답변: 예, URScript는 서브프로그램을 호출하는 방법을 제공합니다. 루프 내부에서 다음과 같이 서브프로그램을 호출할 수 있습니다.\n",
            "\n",
            "```python\n",
            "begin\n",
            "   ...\n",
            "    call_program(\"subprogram_name\");\n",
            "   ...\n",
            "end\n",
            "```\n",
            "\n",
            "❓ 질문 입력 (종료: exit): 트리거가 1일 때 로봇을 뒤로 움직이게 하려면 어케함\n",
            "\n",
            "🟢 답변: 다음 코드를 사용하여 트리거가 1일 때 로봇을 뒤로 움직이게 할 수 있습니다.\n",
            "```c++\n",
            "void trigger1() {\n",
            "  if (comm_pos_2) {\n",
            "    move_to_point(pos_2, 0.5); // 0.5 : 속도\n",
            "  }\n",
            "}\n",
            "```\n",
            "이 코드에서는 `trigger1()`이라는 함수를 정의하고, `comm_pos_2`라는 변수가 `true`일 때, `pos_2` 위치로 로봇을 움직인다. `move_to_point()` 함수는 로봇이 지정된 위치로 이동하는 함수입니다. 이 함수는 속도 파라미터(`0.5`)를 받아 로봇의 이동 속도를 설정합니다.\n",
            "\n",
            "❓ 질문 입력 (종료: exit): TCP 너무 높음 어떡함\n",
            "\n",
            "🟢 답변: TCP 높이를 줄이기 위해 다음 단계를 따르세요.\n",
            "1. Polyscope에서 TCP 절차즈를 탭합니다.\n",
            "2. 새로운 TCP를 만드세요.\n",
            "3. 원하는 TCP 모델을 선택하세요.\n",
            "4. TCP 모델을 편집하고 TCP 높이를 줄이세요.\n",
            "5. 변경 사항을 Polyscope에 저장하세요.\n",
            "6. 생성한 TCP를 장비에 적용하세요.\n",
            "\n",
            "❓ 질문 입력 (종료: exit): 트리에서 노드를 모 찾겠어요???\n",
            "\n",
            "🟢 답변: 트리에서 특정 노드를 찾기 위해서는 트리의 루트에서부터 시작하여 원하는 노드가 있는 위치로 내려가면서 현재 노드와 비교하고, 원하는 노드를 발견하면 그 노드를 반환합니다. 이를 위해 트리의 구조와 노드 정보가 필요합니다.\n",
            "예를 들어, 트리가 다음과 같이 구성되어 있다고 하면, 노드 2를 찾는 방법은 다음과 같습니다.\n",
            "\n",
            "* 트리의 루트인 노드 0을 가져옵니다.\n",
            "* 노드 0의 자식 노드인 노드 1을 가져옵니다.\n",
            "* 노드 1의 자식 노드 중에서 원하는 노드인 노드 2를 비교하며 찾습니다.\n",
            "* 찾은 노드 2를 반환합니다.\n",
            "\n",
            "❓ 질문 입력 (종료: exit): URCap 계속 꺼짐 설치도 안 됨\n",
            "\n",
            "🟢 답변: URCap 설치가 되지 않는 경우, SDK 다운로드를 다시 해주거나, 설치 과정이 잘못되었다고 판단되는 경우에는 SDK 설치 방법을 찾아보고 다시 시도해주세요.\n",
            "\n",
            "❓ 질문 입력 (종료: exit): Polyscope 5.12에서 외부 TCP 보정을 사용할 수 있나요?\n",
            "\n",
            "🟢 답변: 아니요, Polyscope 5.12에서는 외부 TCP 보정이 지원되지 않습니다.\n",
            "단, API에 의해 TCPModel을 사용하여 현재 사용 가능한 TCP의 정보를 가져올 수 있으며, TCPContributionModel을 사용하여 사용자에게 TCP 목록에 추가 할 수 있습니다.\n",
            "\n",
            "❓ 질문 입력 (종료: exit): 로봇을 초기화하는 가장 좋은 방법은 무엇인가요?\n",
            "\n",
            "🟢 답변: 로봇을 초기화하려면 우선 로봇의 모든 웨이포인트를 설정하고 이동을 시작하여 로봇을 원하는 위치로 옮겨야 합니다. 그런 다음, 로봇에서 모든 센서와 기능을 재설정하고 로봇의 시리얼 번호를 재설정하여 로봇을 초기화할 수 있습니다. 이러한 과정을 자동화하기 위해서는 로봇의 소프트웨어 개발 킷(SDK)을 사용하며, 이를 통해 로봇의 초기화 과정을 자동화할 수 있습니다.\n",
            "\n",
            "❓ 질문 입력 (종료: exit): exit\n",
            "\n",
            "🔚 종료합니다.\n"
          ]
        }
      ],
      "source": [
        "!python rag_final.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "69e402e97e224de6a796fc89acd6b6af",
            "8cff2748d6d74e44b2a5175711edd62b",
            "21984f351a834913b46b34f9020d4048",
            "6f00dd36207d4a47aa251248a12a6859",
            "bb2e6a5ae8e84b30b271c28be3c03eec",
            "62957d2b0d0a4616bba1f601896bf692",
            "f59fc112b4f9430f8dac872124e0e250",
            "e41b1383506c496d8f8f3f1af14134fd",
            "02d28e4c33ce4d7780af037c0f3776f1",
            "abce6e9473c5485ba5d5d6b3cf063b6d",
            "1c3997b20a964242844f6fc134b06394"
          ]
        },
        "id": "xYbZFozJ8ehH",
        "outputId": "da83565f-f4d3-49f4-9f9d-65dc8975f67f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "69e402e97e224de6a796fc89acd6b6af",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "❓ 질문 입력 (종료: exit): URScript에서 MoveJ 명령어에 블렌드 반경을 설정하려면 어떻게 해야 하나요?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🟢 답변: MoveJ 명령어에 블렌드 반경을 설정하려면, 다음과 같이 작성하시면 됩니다.\n",
            "```\n",
            "movej(joint_positions, joint_velocities, joint_accelerations, blend_radius)\n",
            "```\n",
            "blend\\_radius는 블렌드 반경을 의미하며, 실수 값으로 설정할 수 있습니다.\n",
            "\n",
            "❓ 질문 입력 (종료: exit): URCap 개발 시 C207A0 오류는 무엇을 의미하나요?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🟢 답변: C207A0 오류는 URCap 개발 중 발생할 수 있는 일반적인 오류입니다. 이 오류는 일반적으로 URCap 개발 중 사용자가 사용하지 않는 코어 패키지를 사용하여 URCap을 구동하려는 시도로 인해 발생합니다. 이 오류를 해결하기 위해서는 사용하지 않는 코어 패키지를 제거하거나 사용하지 않는 코어 패키지를 대체하는 방법을 찾아야 합니다.\n",
            "\n",
            "❓ 질문 입력 (종료: exit): 트리거가 1일 때 로봇을 뒤로 움직이게 하려면 어케함\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🟢 답변: ```csharp\n",
            "LOOP()를 사용하여 트리거가 1일 때 로봇을 뒤로 움직이는 코드를 작성할 수 있습니다.\n",
            "\n",
            "예시 코드:\n",
            "\n",
            "LOOP(5) { // 5번 반복\n",
            "    MOVE_TO(목표 위치); // 목표 위치로 이동\n",
            "    WAIT_UNTIL_REACHED(); // 목표 위치에 도착하기를 기다림\n",
            "    MOVE_LINEAR(뒤로 이동할 거리, 속도); // 뒤로 이동\n",
            "}\n",
            "```\n",
            "이 코드는 목표 위치로 이동하고, 목표 위치에 도착하면 뒤로 이동하는 것을 반복합니다. 반복 횟수는 5로 설정되어 있지만, 필요에 따라 조정할 수 있습니다.\n",
            "\n",
            "❓ 질문 입력 (종료: exit): TCP 너무 높음 어떡함\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🟢 답변: TCP 높이를 조정하려면 다음 단계를 따르세요.\n",
            "1. Polyscope에서 TCP 즐비저를 열고 새로운 TCP를 만듭니다.\n",
            "2. 새로운 TCP에 적절한 포인트를 추가하고 필요에 따라 각도를 조정합니다.\n",
            "3. 새로운 TCP를 저장하고 활성 TCP로 설정합니다.\n",
            "4. 새로운 TCP를 사용하여 재학습을 수행합니다.\n",
            "\n",
            "❓ 질문 입력 (종료: exit): 로봇을 초기화하는 가장 좋은 방법은 무엇인가요?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🟢 답변: 로봇을 초기화하는 가장 좋은 방법은 로봇의 초기 위치로 이동하고 로봇의 모든 잠재적인 작업을 중지하는 것입니다. 이를 위해서는 MoveJ 또는 MoveL 명령을 사용하여 로봇의 초기 위치로 이동시키고, 로봇의 모든 작업을 중지하기 위해서는 StopJ 또는 StopL 명령을 사용하면 됩니다.\n",
            "\n",
            "❓ 질문 입력 (종료: exit): Polyscope 5.12에서 외부 TCP 보정을 사용할 수 있나요?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🟢 답변: Polyscope 5.12에서는 외부 TCP 보정이 지원되지 않습니다. 따라서 외부 TCP 보정을 사용하려면 다른 방법이 필요합니다.\n",
            "\n",
            "❓ 질문 입력 (종료: exit): 로봇을 초기화하는 가장 좋은 방법은 무엇인가요?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🟢 답변: 로봇을 초기화하는 가장 좋은 방법은 로봇의 초기 위치로 이동하고 로봇의 모든 잠재적인 작업을 중지하는 것입니다. 이를 위해서는 MoveJ 또는 MoveL 명령을 사용하여 로봇의 초기 위치로 이동시키고, 로봇의 모든 작업을 중지하기 위해서는 StopJ 또는 StopL 명령을 사용하면 됩니다.\n",
            "\n",
            "❓ 질문 입력 (종료: exit): URCap 개발 시 C207A0 오류는 무엇을 의미하나요?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🟢 답변: C207A0 오류는 URCap 개발 중 발생할 수 있는 일반적인 오류입니다. 이 오류는 일반적으로 URCap 개발 중 사용자가 사용하지 않는 코어 패키지를 사용하여 URCap을 구동하려는 시도로 인해 발생합니다. 이 오류를 해결하기 위해서는 사용하지 않는 코어 패키지를 제거하거나 사용하지 않는 코어 패키지를 대체하는 방법을 찾아야 합니다.\n",
            "\n",
            "❓ 질문 입력 (종료: exit): UR5e의 0번 포트에서 아날로그 입력을 읽으려면 어떻게 하나요?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🟢 답변: UR5e의 0번 포트는 아날로그 입력을 받지 않습니다. 아날로그 입력을 받기 위해서는 1번 포트(A) 또는 2번 포트(B)를 사용하십시오. 각 포트에는 0~10V 범위의 입력이 가능합니다.\n",
            "\n",
            "❓ 질문 입력 (종료: exit): exit\n",
            "\n",
            "🔚 종료합니다.\n"
          ]
        }
      ],
      "source": [
        "#rag_final.py\n",
        "import pandas as pd\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_huggingface import HuggingFacePipeline, HuggingFaceEmbeddings\n",
        "\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    BitsAndBytesConfig,\n",
        "    pipeline,\n",
        ")\n",
        "\n",
        "# 1. 모델 설정 (4bit 양자화)\n",
        "model_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    llm_int8_enable_fp32_cpu_offload=True,\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=quantization_config,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "text_generator = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=2048,\n",
        "    do_sample=True, #경고 무시하기 위해 true로 설정\n",
        "    repetition_penalty=1.03,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        ")\n",
        "llm = HuggingFacePipeline(pipeline=text_generator)\n",
        "\n",
        "# 2. 데이터 불러오기\n",
        "csv_path = \"/content/drive/MyDrive/ColabNotebooks/cleaned_noimage_.csv\"\n",
        "df = pd.read_csv(csv_path, encoding=\"ISO-8859-1\")\n",
        "\n",
        "# 3. 문서 분할\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=100)\n",
        "combined_texts = (df[\"question\"].fillna(\"\") + \" \" + df[\"answer\"].fillna(\"\")).tolist()\n",
        "docs = text_splitter.create_documents(combined_texts)\n",
        "\n",
        "# 4. 벡터스토어\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "vectorstore = FAISS.from_documents(docs, embeddings)\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
        "\n",
        "# 5. 프롬프트 템플릿\n",
        "prompt_template = \"\"\"\n",
        "제공된 다음 문맥 정보를 바탕으로, 사용자 질문에 대한 **한국어로 된 간결한 답변**만 작성해주세요.\n",
        "다른 정보나 서론, 추가 설명은 일절 포함하지 마세요. 답변은 오직 한국어로만 구성되어야 합니다.\n",
        "\n",
        "문맥:\n",
        "{context}\n",
        "\n",
        "사용자 질문: {question}\n",
        "\n",
        "답변:\n",
        "\"\"\"\n",
        "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
        "\n",
        "# 6. QA 체인 구성\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True,\n",
        "    input_key=\"question\",\n",
        "    chain_type_kwargs={\"prompt\": PROMPT},\n",
        ")\n",
        "\n",
        "# 7. 질의 실행\n",
        "if __name__ == \"__main__\":\n",
        "    while True:\n",
        "        user_query = input(\"\\n❓ 질문 입력 (종료: exit): \")\n",
        "        if user_query.strip().lower() == \"exit\":\n",
        "            print(\"\\n🔚 종료합니다.\")\n",
        "            break\n",
        "\n",
        "        result = qa_chain.invoke({\"question\": user_query})\n",
        "        response_text = result['result']\n",
        "\n",
        "        if \"답변:\" in response_text:\n",
        "            cleaned = response_text.split(\"답변:\", 1)[1].strip()\n",
        "        else:\n",
        "            cleaned = response_text.strip()\n",
        "\n",
        "        print(\"\\n🟢 답변:\", cleaned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t15wMwhxrxWI",
        "outputId": "bbddce51-d2cc-4102-bdda-024a9bfcf05f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain-huggingface\n",
            "  Downloading langchain_huggingface-0.3.0-py3-none-any.whl.metadata (996 bytes)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.65 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.3.65)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.21.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.30.2 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.33.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (1.1.3)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.3.45)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (1.33)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (2.11.7)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.30.2->langchain-huggingface) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.30.2->langchain-huggingface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.30.2->langchain-huggingface) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.30.2->langchain-huggingface) (2025.6.15)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (1.3.1)\n",
            "Downloading langchain_huggingface-0.3.0-py3-none-any.whl (27 kB)\n",
            "Installing collected packages: langchain-huggingface\n",
            "Successfully installed langchain-huggingface-0.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain-huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "679e102f991e45b6965ea5e7fd5b22a4",
            "8491d3893de74ca6ad05e15fb0751fb9",
            "4a20b31b1c4e481aadd94dbc31bcf311",
            "3011091118da4ee7b3ea8d223c9d31e9",
            "4cd3f939d27145e9b6ebb0d29954c6e3",
            "bc7b543b4ce14fab9d2fd9de3e40bd5b",
            "be7c9625b1394ed08d5a2e91d7f9070f",
            "51437a8bb93d472098c9d40f808dbeb0",
            "b565106793bb43da88b63a5c225e865b",
            "e9f3f8574d2e41cf87e9036a546f3cab",
            "ad6145c8d9e94b24a4d1746d118b01ac"
          ]
        },
        "id": "pEMZzPSuk1iP",
        "outputId": "dd0e16bc-e331-4700-b2ff-dbb642dada16"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "679e102f991e45b6965ea5e7fd5b22a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "# rag.py\n",
        "\n",
        "import pandas as pd\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    BitsAndBytesConfig,\n",
        "    pipeline,\n",
        ")\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "\n",
        "_llm = None\n",
        "_embeddings = None\n",
        "_retriever = None\n",
        "_qa_chain = None\n",
        "\n",
        "def load_rag_components():\n",
        "    \"\"\"\n",
        "    RAG 시스템에 필요한 모든 컴포넌트(LLM, 임베딩 모델, 벡터스토어, QA 체인)를 로드합니다.\n",
        "    이 함수는 외부에서 호출되어야 하며, 컴포넌트가 로드되지 않았을 때만 실행됩니다.\n",
        "    \"\"\"\n",
        "    global _llm, _embeddings, _retriever, _qa_chain\n",
        "\n",
        "    if _qa_chain is not None:\n",
        "        return True\n",
        "\n",
        "    # 1.1. LLM 설정 (4bit 양자화)\n",
        "    model_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
        "    quantization_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_compute_dtype=torch.float16,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "        _model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_id,\n",
        "            quantization_config=quantization_config,\n",
        "            device_map=\"auto\",\n",
        "        )\n",
        "        text_generator = pipeline(\n",
        "            \"text-generation\",\n",
        "            model=_model,\n",
        "            tokenizer=tokenizer,\n",
        "            max_new_tokens=2048,\n",
        "            do_sample=True,\n",
        "            repetition_penalty=1.03,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "        )\n",
        "        _llm = HuggingFacePipeline(pipeline=text_generator)\n",
        "    except Exception as e:\n",
        "        return False\n",
        "\n",
        "    # 1.2. 데이터 불러오기\n",
        "    csv_path = \"/content/drive/MyDrive/MyDrive/ColabNotebooks/cleaned_noimage_.csv\"\n",
        "    try:\n",
        "        df = pd.read_csv(csv_path, encoding=\"ISO-8859-1\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "\n",
        "        return False\n",
        "    except Exception as e:\n",
        "\n",
        "        return False\n",
        "\n",
        "    # 1.3. 문서 분할\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=100)\n",
        "    combined_texts = (\n",
        "        df[\"question\"].fillna(\"\") + \" \" + df[\"answer\"].fillna(\"\")\n",
        "    ).tolist()\n",
        "    docs = text_splitter.create_documents(combined_texts)\n",
        "    print(f\"총 {len(docs)}개의 문서 청크 생성.\")\n",
        "\n",
        "    # 1.4. 벡터스토어\n",
        "    try:\n",
        "        _embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "        _vectorstore = FAISS.from_documents(docs, _embeddings)\n",
        "        _retriever = _vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
        "\n",
        "    except Exception as e:\n",
        "        return False\n",
        "\n",
        "    # 1.5. 프롬프트\n",
        "    prompt_template = \"\"\"\n",
        "    제공된 다음 문맥 정보를 바탕으로, 사용자 질문에 대한 **한국어로 된 간결한 답변**만 작성해주세요.\n",
        "    다른 정보나 서론, 추가 설명은 일절 포함하지 마세요. 답변은 오직 한국어로만 구성되어야 합니다.\n",
        "\n",
        "    문맥:\n",
        "    {context}\n",
        "\n",
        "    사용자 질문: {question}\n",
        "\n",
        "    답변:\n",
        "    \"\"\"\n",
        "    PROMPT = PromptTemplate(\n",
        "        template=prompt_template,\n",
        "        input_variables=[\"context\", \"question\"],\n",
        "    )\n",
        "\n",
        "    # 1.6. QA 체인\n",
        "    _qa_chain = RetrievalQA.from_chain_type(\n",
        "        llm=_llm,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=_retriever,\n",
        "        return_source_documents=True,\n",
        "        input_key=\"question\",\n",
        "        chain_type_kwargs={\"prompt\": PROMPT},\n",
        "    )\n",
        "    return True\n",
        "\n",
        "def get_qa_chain():\n",
        "    \"\"\"\n",
        "    초기화된 QA 체인 인스턴스를 반환합니다.\n",
        "    만약 아직 로드되지 않았다면, load_rag_components()를 호출하여 로드를 시도합니다.\n",
        "    \"\"\"\n",
        "    if _qa_chain is None:\n",
        "        if not load_rag_components():\n",
        "            return None\n",
        "    return _qa_chain\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    if get_qa_chain():\n",
        "        user_query = \"협동로봇의 주요 안전 수칙은 무엇인가요?\"\n",
        "        result = _qa_chain.invoke({\"question\": user_query})\n",
        "\n",
        "        generated_text = result['result']\n",
        "        answer_prefix_ko = \"답변:\"\n",
        "        cleaned_answer = \"\"\n",
        "        if answer_prefix_ko in generated_text:\n",
        "            cleaned_answer = generated_text.split(answer_prefix_ko, 1)[1].strip()\n",
        "        else:\n",
        "            cleaned_answer = generated_text\n",
        "\n",
        "        # print(f\"\\n--- 테스트 답변 ---\") # 제거\n",
        "        # print(cleaned_answer) # 제거\n",
        "        # print(\"\\n--- 참고 문서 ---\") # 제거\n",
        "        # for i, doc in enumerate(result['source_documents']): # 제거\n",
        "        #     print(f\"- 문서 {i+1}: {doc.page_content[:150]}...\") # 제거"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 296,
          "referenced_widgets": [
            "58e1749bb881475a87eb480fdf2d2498",
            "da538ca2b805410195005208e96f0b52",
            "881403dde56e4fafbc39beb6cdba7fe0",
            "bcf2b07e3afd42bfb09f4a061810c3c0",
            "7563c39b76024e449f215f8fb5786f10",
            "81d2752f0ccd4f19abf9897d7e6659da",
            "46937c1274b34c0f87f45dce91cd6d62",
            "ad69d8dfe90046f893e2c03b50e9a920",
            "0cc76490fe1447af8af5969c32bc22b2",
            "a0368276da774448847cd29d266d5f8d",
            "d5ef490b389745d9a44b1b7ee9e35f40"
          ]
        },
        "id": "FiRpoV7Vt8Yc",
        "outputId": "3720ba88-50b0-415b-ac2f-3996e31470bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ RAG 시스템 초기화 중...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58e1749bb881475a87eb480fdf2d2498",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "/tmp/ipython-input-5-2308166378.py:54: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
            "  _llm = HuggingFacePipeline(pipeline=text_gen)\n",
            "/tmp/ipython-input-5-2308166378.py:75: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  _embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📄 총 561개의 문서 청크 생성됨.\n",
            "✅ 시스템 준비 완료! 질문을 입력하세요.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🟢 답변: 로봇을 초기화하는 가장 좋은 방법은 로봇의 초기 위치로 이동하고 로봇의 모든 잠재적인 작업을 중지하는 것입니다. 이를 위해서는 MoveJ 또는 MoveL 명령을 사용하여 로봇의 초기 위치로 이동시키고, 로봇의 모든 작업을 중지하기 위해서는 StopJ 또는 StopL 명령을 사용하면 됩니다.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    BitsAndBytesConfig,\n",
        "    pipeline,\n",
        ")\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "\n",
        "# 전역 변수\n",
        "_llm = None\n",
        "_embeddings = None\n",
        "_retriever = None\n",
        "_qa_chain = None\n",
        "\n",
        "def load_rag_components():\n",
        "    global _llm, _embeddings, _retriever, _qa_chain\n",
        "\n",
        "    if _qa_chain is not None:\n",
        "        return True  # 이미 로드됨\n",
        "\n",
        "    # 1. 모델 설정\n",
        "    model_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
        "    quant_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_compute_dtype=torch.float16,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_id,\n",
        "            quantization_config=quant_config,\n",
        "            device_map=\"auto\"\n",
        "        )\n",
        "        text_gen = pipeline(\n",
        "            \"text-generation\",\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            max_new_tokens=2048,\n",
        "            do_sample=False,\n",
        "            repetition_penalty=1.03,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "        _llm = HuggingFacePipeline(pipeline=text_gen)\n",
        "    except Exception as e:\n",
        "        print(f\" 모델 로딩 오류: {e}\")\n",
        "        return False\n",
        "\n",
        "    # 2. CSV 데이터 불러오기\n",
        "    csv_path = \"/content/drive/MyDrive/ColabNotebooks/cleaned_noimage_.csv\"\n",
        "    try:\n",
        "        df = pd.read_csv(csv_path, encoding=\"ISO-8859-1\")\n",
        "    except Exception as e:\n",
        "        print(f\" CSV 로딩 오류: {e}\")\n",
        "        return False\n",
        "\n",
        "    # 3. 문서 분할\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=100)\n",
        "    combined_texts = (df[\"question\"].fillna(\"\") + \" \" + df[\"answer\"].fillna(\"\")).tolist()\n",
        "    docs = text_splitter.create_documents(combined_texts)\n",
        "    print(f\"📄 총 {len(docs)}개의 문서 청크 생성됨.\")\n",
        "\n",
        "    # 4. 벡터스토어 및 임베딩\n",
        "    try:\n",
        "        _embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "        vectorstore = FAISS.from_documents(docs, _embeddings)\n",
        "        _retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
        "    except Exception as e:\n",
        "        print(f\" 벡터스토어 구축 오류: {e}\")\n",
        "        return False\n",
        "\n",
        "    # 5. 프롬프트 템플릿\n",
        "    prompt_template = \"\"\"\n",
        "제공된 다음 문맥 정보를 바탕으로, 사용자 질문에 대한 **한국어로 된 간결한 답변**만 작성해주세요.\n",
        "다른 정보나 서론, 추가 설명은 일절 포함하지 마세요. 답변은 오직 한국어로만 구성되어야 합니다.\n",
        "\n",
        "문맥:\n",
        "{context}\n",
        "\n",
        "사용자 질문: {question}\n",
        "\n",
        "답변:\n",
        "\"\"\"\n",
        "    PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
        "\n",
        "    # 6. QA 체인 구성\n",
        "    _qa_chain = RetrievalQA.from_chain_type(\n",
        "        llm=_llm,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=_retriever,\n",
        "        return_source_documents=False,\n",
        "        input_key=\"question\",\n",
        "        chain_type_kwargs={\"prompt\": PROMPT},\n",
        "    )\n",
        "\n",
        "    return True\n",
        "\n",
        "def get_qa_chain():\n",
        "    global _qa_chain\n",
        "    if _qa_chain is None:\n",
        "        if not load_rag_components():\n",
        "            return None\n",
        "    return _qa_chain\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"✅ RAG 시스템 초기화 중...\")\n",
        "    if get_qa_chain():\n",
        "        print(\"✅ 시스템 준비 완료! 질문을 입력하세요.\")\n",
        "        while True:\n",
        "            user_query = input(\"\\n❓ 질문 입력 (exit 입력 시 종료): \")\n",
        "            if user_query.lower() in [\"exit\", \"quit\", \"종료\"]:\n",
        "                print(\"👋 종료합니다.\")\n",
        "                break\n",
        "\n",
        "            result = _qa_chain.invoke({\"question\": user_query})\n",
        "            generated_text = result['result']\n",
        "\n",
        "            # 답변 정제\n",
        "            answer_prefix = \"답변:\"\n",
        "            if answer_prefix in generated_text:\n",
        "                cleaned_answer = generated_text.split(answer_prefix, 1)[1].strip()\n",
        "            else:\n",
        "                cleaned_answer = generated_text\n",
        "\n",
        "            print(\"🟢 답변:\", cleaned_answer)\n",
        "    else:\n",
        "        print(\"❌ 시스템 로딩 실패. 확인 후 다시 실행하세요.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Rp7ctlbcYIkv",
        "outputId": "24895e31-1c1f-4a27-c09f-ee4a9118328a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: read).\n",
            "The token `as` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `as`\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAZwwgDaQjfQ",
        "outputId": "7081cf0a-fc1c-408f-c23e-84a4a32b4013"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5_txQ9n6HuZ"
      },
      "source": [
        "# RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b411Sq5g1qMF"
      },
      "source": [
        "RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyqL6lRAGflM"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02d28e4c33ce4d7780af037c0f3776f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0cc76490fe1447af8af5969c32bc22b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1c3997b20a964242844f6fc134b06394": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21984f351a834913b46b34f9020d4048": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e41b1383506c496d8f8f3f1af14134fd",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_02d28e4c33ce4d7780af037c0f3776f1",
            "value": 3
          }
        },
        "3011091118da4ee7b3ea8d223c9d31e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9f3f8574d2e41cf87e9036a546f3cab",
            "placeholder": "​",
            "style": "IPY_MODEL_ad6145c8d9e94b24a4d1746d118b01ac",
            "value": " 3/3 [00:17&lt;00:00,  5.83s/it]"
          }
        },
        "46937c1274b34c0f87f45dce91cd6d62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a20b31b1c4e481aadd94dbc31bcf311": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51437a8bb93d472098c9d40f808dbeb0",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b565106793bb43da88b63a5c225e865b",
            "value": 3
          }
        },
        "4cd3f939d27145e9b6ebb0d29954c6e3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51437a8bb93d472098c9d40f808dbeb0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58e1749bb881475a87eb480fdf2d2498": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da538ca2b805410195005208e96f0b52",
              "IPY_MODEL_881403dde56e4fafbc39beb6cdba7fe0",
              "IPY_MODEL_bcf2b07e3afd42bfb09f4a061810c3c0"
            ],
            "layout": "IPY_MODEL_7563c39b76024e449f215f8fb5786f10"
          }
        },
        "62957d2b0d0a4616bba1f601896bf692": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "679e102f991e45b6965ea5e7fd5b22a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8491d3893de74ca6ad05e15fb0751fb9",
              "IPY_MODEL_4a20b31b1c4e481aadd94dbc31bcf311",
              "IPY_MODEL_3011091118da4ee7b3ea8d223c9d31e9"
            ],
            "layout": "IPY_MODEL_4cd3f939d27145e9b6ebb0d29954c6e3"
          }
        },
        "69e402e97e224de6a796fc89acd6b6af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8cff2748d6d74e44b2a5175711edd62b",
              "IPY_MODEL_21984f351a834913b46b34f9020d4048",
              "IPY_MODEL_6f00dd36207d4a47aa251248a12a6859"
            ],
            "layout": "IPY_MODEL_bb2e6a5ae8e84b30b271c28be3c03eec"
          }
        },
        "6f00dd36207d4a47aa251248a12a6859": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abce6e9473c5485ba5d5d6b3cf063b6d",
            "placeholder": "​",
            "style": "IPY_MODEL_1c3997b20a964242844f6fc134b06394",
            "value": " 3/3 [00:17&lt;00:00,  5.68s/it]"
          }
        },
        "7563c39b76024e449f215f8fb5786f10": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81d2752f0ccd4f19abf9897d7e6659da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8491d3893de74ca6ad05e15fb0751fb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc7b543b4ce14fab9d2fd9de3e40bd5b",
            "placeholder": "​",
            "style": "IPY_MODEL_be7c9625b1394ed08d5a2e91d7f9070f",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "881403dde56e4fafbc39beb6cdba7fe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad69d8dfe90046f893e2c03b50e9a920",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0cc76490fe1447af8af5969c32bc22b2",
            "value": 3
          }
        },
        "8cff2748d6d74e44b2a5175711edd62b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62957d2b0d0a4616bba1f601896bf692",
            "placeholder": "​",
            "style": "IPY_MODEL_f59fc112b4f9430f8dac872124e0e250",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "a0368276da774448847cd29d266d5f8d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abce6e9473c5485ba5d5d6b3cf063b6d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad6145c8d9e94b24a4d1746d118b01ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad69d8dfe90046f893e2c03b50e9a920": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b565106793bb43da88b63a5c225e865b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb2e6a5ae8e84b30b271c28be3c03eec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc7b543b4ce14fab9d2fd9de3e40bd5b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcf2b07e3afd42bfb09f4a061810c3c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0368276da774448847cd29d266d5f8d",
            "placeholder": "​",
            "style": "IPY_MODEL_d5ef490b389745d9a44b1b7ee9e35f40",
            "value": " 3/3 [00:17&lt;00:00,  5.71s/it]"
          }
        },
        "be7c9625b1394ed08d5a2e91d7f9070f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5ef490b389745d9a44b1b7ee9e35f40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da538ca2b805410195005208e96f0b52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81d2752f0ccd4f19abf9897d7e6659da",
            "placeholder": "​",
            "style": "IPY_MODEL_46937c1274b34c0f87f45dce91cd6d62",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "e41b1383506c496d8f8f3f1af14134fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9f3f8574d2e41cf87e9036a546f3cab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f59fc112b4f9430f8dac872124e0e250": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}